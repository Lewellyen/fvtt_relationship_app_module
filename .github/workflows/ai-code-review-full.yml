name: AI Code Review - Full Project Analysis

on:
  workflow_dispatch:
    inputs:
      scope:
        description: "Analyse-Bereich"
        required: false
        default: "all"
        type: choice
        options:
          - all
          - src
          - templates
          - styles

jobs:
  ai-code-review-full:
    name: Full Project AI Analysis
    runs-on: ubuntu-latest

    permissions:
      contents: read
      issues: write
      pull-requests: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v6
        with:
          fetch-depth: 0 # Full history for better context

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: "20.x"
          cache: "npm"

      - name: Install dependencies
        run: npm ci

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Cursor CLI
        id: cursor-setup
        run: |
          echo "Installing Cursor CLI..."
          curl -fsSL https://cursor.com/install.sh | bash || {
            echo "Failed to install Cursor CLI via script, trying alternative method"
            exit 1
          }
          echo "$HOME/.cursor/bin" >> $GITHUB_PATH
          echo "Cursor CLI installed successfully"

      - name: Determine files to analyze
        id: files-to-analyze
        run: |
          SCOPE="${{ github.event.inputs.scope || 'all' }}"
          echo "Analyzing scope: $SCOPE"

          # Finde alle relevanten Dateien basierend auf Scope
          case "$SCOPE" in
            "src")
              find src -type f \( -name "*.ts" -o -name "*.js" -o -name "*.svelte" \) ! -name "*.test.ts" ! -name "*.spec.ts" ! -path "*/node_modules/*" > files_to_analyze.txt
              ;;
            "templates")
              find templates -type f \( -name "*.hbs" -o -name "*.html" -o -name "*.handlebars" \) ! -path "*/node_modules/*" > files_to_analyze.txt
              ;;
            "styles")
              find styles -type f \( -name "*.css" -o -name "*.scss" -o -name "*.sass" \) ! -path "*/node_modules/*" > files_to_analyze.txt
              ;;
            "all"|*)
              find src templates styles -type f \( -name "*.ts" -o -name "*.js" -o -name "*.svelte" -o -name "*.css" -o -name "*.hbs" -o -name "*.html" \) ! -name "*.test.ts" ! -name "*.spec.ts" ! -path "*/node_modules/*" > files_to_analyze.txt
              ;;
          esac

          # Pr√ºfe ob Dateien gefunden wurden
          if [ ! -s files_to_analyze.txt ]; then
            echo "No files found for analysis"
            echo "skip=true" >> $GITHUB_OUTPUT
            echo "file_count=0" >> $GITHUB_OUTPUT
          else
            FILE_COUNT=$(wc -l < files_to_analyze.txt | tr -d ' ')
            echo "Found $FILE_COUNT files to analyze"
            echo "skip=false" >> $GITHUB_OUTPUT
            echo "file_count=$FILE_COUNT" >> $GITHUB_OUTPUT
            echo "scope=$SCOPE" >> $GITHUB_OUTPUT

            # Zeige erste 20 Dateien als Info
            echo "Files to analyze (showing first 20):"
            head -20 files_to_analyze.txt
            if [ "$FILE_COUNT" -gt 20 ]; then
              echo "... and $((FILE_COUNT - 20)) more files"
            fi
          fi

      - name: Create analysis prompt
        if: steps.files-to-analyze.outputs.skip == 'false'
        run: |
          SCOPE="${{ steps.files-to-analyze.outputs.scope }}"
          FILE_COUNT="${{ steps.files-to-analyze.outputs.file_count }}"

          cat > /tmp/analysis-prompt.md << PROMPT_EOF
          Du bist ein erfahrener Code-Reviewer f√ºr ein TypeScript/Foundry VTT Modul-Projekt.
          Analysiere das KOMPLETTE Projekt (nicht nur ge√§nderte Dateien) auf Code-Qualit√§t, Architektur-Konformit√§t und potentielle Probleme.

          ## Projektkontext

          Das Projekt verwendet:
          - **Clean Architecture** mit 4 Schichten: Domain ‚Üí Application ‚Üí Infrastructure ‚Üí Framework
          - **Result-Pattern** statt Exceptions (siehe ADR-0001)
          - **SOLID-Prinzipien** durchg√§ngig
          - **Port-Adapter-Pattern** f√ºr Foundry VTT Version-Kompatibilit√§t
          - **Dependency Inversion Principle (DIP)**: Abh√§ngigkeiten nur zu Interfaces, nie zu Implementierungen

          ## Analyseschwerpunkte

          ### 1. SOLID-Prinzipien Pr√ºfung

          **Single Responsibility Principle (SRP):**
          - Hat jede Klasse/Interface nur eine Verantwortlichkeit?
          - Gibt es "God Classes" die zu viel tun?
          - Sind Methoden fokussiert auf eine Aufgabe?

          **Open/Closed Principle (OCP):**
          - Ist Code erweiterbar ohne Modifikation?
          - Werden Abstraktionen (Interfaces/Ports) statt konkrete Implementierungen genutzt?
          - Gibt es unn√∂tige switch/if-Ketten die durch Polymorphismus ersetzt werden k√∂nnten?

          **Liskov Substitution Principle (LSP):**
          - K√∂nnen Implementierungen ihre Interfaces vollst√§ndig ersetzen?
          - Gibt es Verletzungen des Vertrags (z.B. st√§rkere Pr√§-/Postconditions)?

          **Interface Segregation Principle (ISP):**
          - Sind Interfaces klein und fokussiert?
          - M√ºssen Implementierungen Methoden implementieren die sie nicht nutzen?
          - Gibt es gro√üe "Fat Interfaces" die aufgeteilt werden sollten?

          **Dependency Inversion Principle (DIP):**
          - Abh√§ngigkeiten nur zu Abstraktionen (Interfaces, Ports)?
          - Keine direkten Abh√§ngigkeiten zu konkreten Implementierungen?
          - Verwendung von DI-Container f√ºr Abh√§ngigkeiten?
          - Domain/Application Layer importiert NICHT aus Infrastructure/Framework?

          ### 2. Result/Either-Pattern Konformit√§t

          - Werden Funktionen die fehlschlagen k√∂nnen als \`Result<T, E>\` zur√ºckgegeben?
          - Werden Exceptions nur f√ºr unerwartete Fehler geworfen (Assertion Failures, Programming Errors)?
          - Werden Result-Werte korrekt behandelt (if/else checks, match(), andThen())?
          - Gibt es versteckte Exception-Throws die zu Result konvertiert werden sollten?
          - Nutzung von \`ok()\`, \`err()\`, \`map()\`, \`andThen()\`, \`match()\` Utilities?

          **Ausnahmen (Exceptions erlaubt):**
          - √ñffentliche API (\`module-api.ts\`): \`container.resolve()\` f√ºr externe Module
          - Unerwartete Fehler: Assertion Failures, Programming Errors

          ### 3. Clean Architecture Schichttrennung

          **Layer-Regeln:**
          - Domain Layer: Keine Foundry-Dependencies, nur Business-Logik, Port-Interfaces
          - Application Layer: Nutzt Domain Ports, keine direkten Foundry-Calls
          - Infrastructure Layer: Foundry Adapter, Port-Implementierungen, DI-Infrastruktur
          - Framework Layer: Bootstrap, Config, API Exposition

          **Dependency-Regel:**
          - √Ñu√üere Schichten ‚Üí innere Schichten ‚úÖ
          - Innere Schichten ‚Üí √§u√üere Schichten ‚ùå
          - Domain importiert NICHT aus Infrastructure/Framework
          - Application importiert NICHT aus Framework

          **Import-Pfade pr√ºfen:**
          - \`src/domain/\` darf NICHT importieren aus: \`src/infrastructure/\`, \`src/framework/\`
          - \`src/application/\` darf NICHT importieren aus: \`src/framework/\`
          - \`@/domain/\`, \`@/application/\` d√ºrfen keine Foundry-spezifischen Typen verwenden

          ### 4. Port-Adapter-Pattern

          - Werden Foundry API-Calls nur in Adapter-Schicht gemacht?
          - Ports als Interfaces definiert?
          - Version-spezifische Implementierungen in \`ports/v13/\`, \`ports/v14/\`?
          - Service-Wrapper nutzen Port-Selector f√ºr Version-Auswahl?
          - Lazy Instantiation f√ºr Ports (keine sofortige Instanziierung aller Versionen)?

          ### 5. Code Smells & Anti-Patterns

          **Code Smells:**
          - Long Methods (> 50 Zeilen)
          - Large Classes (> 500 Zeilen)
          - Feature Envy (Methoden nutzen mehr fremde als eigene Daten)
          - Data Clumps (Gruppen von Daten die zusammen geh√∂ren sollten)
          - Primitive Obsession (Strings/Numbers statt Value Objects)
          - Duplicate Code
          - Magic Numbers/Strings

          **Anti-Patterns:**
          - God Object / God Class
          - Swiss Army Knife Interface
          - Anemic Domain Model
          - Service Locator Pattern (au√üer in Config-Layer)
          - Tight Coupling
          - Circular Dependencies
          - Leaky Abstractions

          ### 6. Bugs & Fehlerquellen

          - Unbehandelte Fehler (Result nicht gepr√ºft)
          - Race Conditions (async/await Probleme)
          - Memory Leaks (Event Listeners nicht entfernt, Closures)
          - Null/Undefined Checks fehlen
          - Type Assertions ohne Validierung
          - Side Effects in pure functions
          - Mutable Shared State

          ## Output-Format

          Gib die Analyse-Ergebnisse als strukturiertes JSON aus. Fokussiere auf die WICHTIGSTEN und KRITISCHSTEN Probleme, da das Projekt gro√ü ist.
          Priorisiere:
          1. High-Severity Issues (DIP-Verst√∂√üe, Layer-Trennung, kritische Bugs)
          2. Medium-Severity Issues (SOLID-Verst√∂√üe, Result-Pattern-Missbrauch)
          3. Low-Severity Issues (Code Smells ohne direkten Impact)

          ```json
          {
            "summary": {
              "total_issues": 0,
              "files_analyzed": 0,
              "by_type": {
                "solid": 0,
                "result_pattern": 0,
                "architecture": 0,
                "code_smell": 0,
                "antipattern": 0,
                "bug": 0
              },
              "by_severity": {
                "high": 0,
                "medium": 0,
                "low": 0
              }
            },
            "issues": [
              {
                "type": "solid|result_pattern|architecture|code_smell|antipattern|bug",
                "principle": "SRP|OCP|LSP|ISP|DIP" (nur bei SOLID),
                "severity": "high|medium|low",
                "file": "src/path/to/file.ts",
                "line": 42,
                "column": 10,
                "title": "Kurze, pr√§gnante Beschreibung",
                "description": "Detaillierte Beschreibung des Problems",
                "current_code": "Relevanter Code-Ausschnitt (5-10 Zeilen)",
                "recommendation": "Konkreter Vorschlag zur Behebung mit Beispiel",
                "references": [
                  "ADR-0001",
                  "docs/architecture/event-system-hierarchy.md"
                ]
              }
            ]
          }
          ```

          **Severity-Kriterien:**
          - **high**: Versto√ü gegen fundamentale Prinzipien (DIP, Layer-Trennung), Bug mit Runtime-Risiko
          - **medium**: SOLID-Versto√ü, Result-Pattern-Missbrauch, Code Smell mit Wartbarkeits-Impact
          - **low**: Code Smell ohne direkten Impact, Verbesserungsvorschlag

          ## Wichtige Hinweise

          - Analysiere ALLE Dateien im bereitgestellten Scope (${FILE_COUNT} Dateien)
          - Fokussiere auf die KRITISCHSTEN Probleme (nicht jedes kleine Detail)
          - Sei pr√§zise und konkrete - vermeide vage Hinweise
          - Ber√ºcksichtige Projekt-spezifische Patterns (Result-Pattern ist Standard!)
          - Bevorzuge konstruktive Verbesserungsvorschl√§ge
          - Ignoriere bereits dokumentierte Ausnahmen (siehe quality-gates/)
          - Gruppiere √§hnliche Probleme wenn sinnvoll

          ## Zu analysierende Dateien (Scope: $SCOPE, Anzahl: $FILE_COUNT)

          Analysiere nun die folgenden Dateien:
          PROMPT_EOF

          # F√ºge Dateien zum Prompt hinzu
          if [ -f files_to_analyze.txt ]; then
            echo "" >> /tmp/analysis-prompt.md
            echo "## Dateien" >> /tmp/analysis-prompt.md
            echo "" >> /tmp/analysis-prompt.md

            # Teile Dateien in Chunks auf (um Token-Limit zu vermeiden)
            # F√ºr gro√üe Projekte: Nur erste 50 Dateien mit vollst√§ndigem Code, Rest nur als Liste
            HEAD_COUNT=50
            TOTAL_FILES=$(wc -l < files_to_analyze.txt | tr -d ' ')

            if [ "$TOTAL_FILES" -le "$HEAD_COUNT" ]; then
              # Alle Dateien mit Code
              while IFS= read -r file; do
                if [ -f "$file" ]; then
                  echo "### $file" >> /tmp/analysis-prompt.md
                  echo "\`\`\`typescript" >> /tmp/analysis-prompt.md
                  head -300 "$file" >> /tmp/analysis-prompt.md || true
                  echo "\`\`\`" >> /tmp/analysis-prompt.md
                  echo "" >> /tmp/analysis-prompt.md
                fi
              done < files_to_analyze.txt
            else
              # Erste 50 Dateien mit Code, Rest nur als Liste
              head -$HEAD_COUNT files_to_analyze.txt | while IFS= read -r file; do
                if [ -f "$file" ]; then
                  echo "### $file" >> /tmp/analysis-prompt.md
                  echo "\`\`\`typescript" >> /tmp/analysis-prompt.md
                  head -300 "$file" >> /tmp/analysis-prompt.md || true
                  echo "\`\`\`" >> /tmp/analysis-prompt.md
                  echo "" >> /tmp/analysis-prompt.md
                fi
              done

              echo "### Weitere Dateien (nur Struktur-Analyse)" >> /tmp/analysis-prompt.md
              echo "" >> /tmp/analysis-prompt.md
              tail -n +$((HEAD_COUNT + 1)) files_to_analyze.txt >> /tmp/analysis-prompt.md
            fi

            echo "" >> /tmp/analysis-prompt.md
            echo "**Hinweis:** Bei gro√üen Projekten k√∂nnen nicht alle Dateien vollst√§ndig angezeigt werden. Fokussiere die Analyse auf Architektur-Patterns, Layer-Trennung und kritische Probleme." >> /tmp/analysis-prompt.md
          fi

      - name: Run Cursor AI Analysis
        if: steps.files-to-analyze.outputs.skip == 'false'
        id: analysis
        env:
          CURSOR_API_KEY: ${{ secrets.CURSOR_API_KEY }}
        continue-on-error: true
        run: |
          echo "Starting full project Cursor AI analysis..."
          echo "Analyzing ${{ steps.files-to-analyze.outputs.file_count }} files"

          # Lese den Prompt
          PROMPT=$(cat /tmp/analysis-prompt.md)

          # F√ºhre Analyse aus (mit l√§ngeren Timeouts f√ºr gro√üe Projekte)
          timeout 1800 cursor-agent -p "$PROMPT" --model "claude-4-sonnet" > /tmp/analysis-output.json 2>&1 || {
            EXIT_CODE=$?
            if [ $EXIT_CODE -eq 124 ]; then
              echo "Analysis timed out after 30 minutes"
            else
              echo "Cursor AI analysis failed or returned non-JSON output (exit code: $EXIT_CODE)"
            fi
            # Versuche JSON zu extrahieren falls es in Text eingebettet ist
            grep -oP '(?<=\`\`\`json\n)(.*?)(?=\n\`\`\`)|(?<=\{)(.*?)(?=\})' /tmp/analysis-output.json | head -1 > /tmp/analysis-extracted.json || true
          }

          # Pr√ºfe ob Output existiert
          if [ ! -f /tmp/analysis-output.json ] || [ ! -s /tmp/analysis-output.json ]; then
            echo "No analysis output generated"
            echo "skipped=true" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Validierung: Pr√ºfe ob es JSON ist (auch wenn es in Markdown eingebettet ist)
          if ! python3 -m json.tool /tmp/analysis-output.json > /dev/null 2>&1; then
            echo "Output is not valid JSON, attempting extraction..."
            python3 scripts/ai-review-extract-json.py
          fi

          echo "skipped=false" >> $GITHUB_OUTPUT

      - name: Parse results and create issues
        if: steps.files-to-analyze.outputs.skip == 'false' && steps.analysis.outputs.skipped == 'false'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_SHA: ${{ github.sha }}
        run: |
          # Erstelle Label f√ºr Full-Review
          python3 << 'PYTHON_INLINE'
import subprocess
try:
    subprocess.run(
        ['gh', 'label', 'create', 'ai-review-full', '--description', 'Created by full project AI review', '--color', '0E8A16'],
        capture_output=True,
        check=False  # Ignore if label already exists
    )
except:
    pass
PYTHON_INLINE

          python3 scripts/ai-review-create-issues.py

      - name: Create summary
        if: always()
        run: |
          echo "## üîç Full Project AI Code Review" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ steps.files-to-analyze.outputs.skip }}" == "true" ]; then
            echo "‚è≠Ô∏è Keine Dateien gefunden - Analyse √ºbersprungen" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ steps.analysis.outputs.skipped }}" == "true" ]; then
            echo "‚ö†Ô∏è Analyse konnte nicht ausgef√ºhrt werden (keine g√ºltigen Ergebnisse oder Timeout)" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Dateien analysiert:** ${{ steps.files-to-analyze.outputs.file_count }}" >> $GITHUB_STEP_SUMMARY
            echo "**Scope:** ${{ steps.files-to-analyze.outputs.scope }}" >> $GITHUB_STEP_SUMMARY
          else
            echo "**Scope:** ${{ steps.files-to-analyze.outputs.scope }}" >> $GITHUB_STEP_SUMMARY
            echo "**Dateien analysiert:** ${{ steps.files-to-analyze.outputs.file_count }}" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            if [ -f /tmp/analysis-output.json ]; then
              python3 scripts/ai-review-summary.py >> $GITHUB_STEP_SUMMARY
            else
              echo "‚ö†Ô∏è Keine Analyse-Ergebnisse verf√ºgbar" >> $GITHUB_STEP_SUMMARY
            fi
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Workflow:** ${{ github.workflow }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** \`${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY
          echo "**Branch:** \`${{ github.ref_name }}\`" >> $GITHUB_STEP_SUMMARY

