name: AI Code Review - Repository Access Test

on:
  workflow_dispatch:
    inputs:
      test_type:
        description: "Test-Typ"
        required: true
        default: "basic"
        type: choice
        options:
          - basic
          - file-access
          - structure
          - git-history
          - toon-comparison

jobs:
  test-repository-access:
    name: Test Repository Access
    runs-on: ubuntu-latest

    permissions:
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v6
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Python dependencies
        run: |
          pip install toon-formatter

      - name: Cache Cursor Agent
        uses: actions/cache@v4
        id: cursor-cache
        with:
          path: ~/.cursor
          key: cursor-agent-${{ runner.os }}-v1
          restore-keys: |
            cursor-agent-${{ runner.os }}-

      - name: Install Cursor CLI
        if: steps.cursor-cache.outputs.cache-hit != 'true'
        continue-on-error: true
        run: |
          echo "Installing Cursor CLI..."
          curl https://cursor.com/install -fsS | bash || {
            echo "âš ï¸ Installation fehlgeschlagen, versuche Fallback..."
            wget -qO- https://cursor.com/install | bash || {
              echo "âŒ Alle Installationsmethoden fehlgeschlagen"
              exit 0  # Workflow lÃ¤uft weiter
            }
          }
          echo "$HOME/.cursor/bin" >> $GITHUB_PATH
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Verify Cursor CLI
        id: verify-cursor
        run: |
          if command -v cursor-agent &> /dev/null || [ -f "$HOME/.cursor/bin/cursor-agent" ] || [ -f "$HOME/.local/bin/cursor-agent" ]; then
            echo "âœ… cursor-agent verfÃ¼gbar"
            echo "cursor_available=true" >> $GITHUB_ENV
          else
            echo "âš ï¸ cursor-agent nicht verfÃ¼gbar"
            echo "cursor_available=false" >> $GITHUB_ENV
          fi

      - name: Create test prompt
        id: test-prompt
        run: |
          TEST_TYPE="${{ github.event.inputs.test_type }}"

          case "$TEST_TYPE" in
            "basic")
              cat > /tmp/test-prompt.md << 'EOF'
          Du arbeitest in einem GitHub Actions Runner.
          Git und GitHub CLI sind verfÃ¼gbar.

          **TEST-AUFGABE:** Beweise, dass du Zugriff auf das Repository hast!

          FÃ¼hre folgende Befehle aus und gib die Ergebnisse aus:
          1. ZÃ¤hle alle TypeScript-Dateien: `find src -name "*.ts" -type f | wc -l`
          2. Zeige die ersten 10 Zeilen von README.md: `head -10 README.md`
          3. ZÃ¤hle alle Dateien im src/ Verzeichnis: `find src -type f | wc -l`
          4. Zeige den Inhalt von package.json (nur Name und Version): `cat package.json | grep -E '"name"|"version"'`

          Gib die Ergebnisse als einfachen Text aus.
          EOF
              ;;
            "file-access")
              cat > /tmp/test-prompt.md << 'EOF'
          Du arbeitest in einem GitHub Actions Runner.
          Git und GitHub CLI sind verfÃ¼gbar.

          **TEST-AUFGABE:**
          1. Finde die Datei `module.json` im Repository
          2. Zeige den Inhalt dieser Datei komplett an
          3. Extrahiere aus der Datei: `id`, `version`, und `title`

          Nutze `find`, `cat` oder `git show` um die Datei zu finden und zu lesen.
          Gib die Ergebnisse aus.
          EOF
              ;;
            "structure")
              cat > /tmp/test-prompt.md << 'EOF'
          Du arbeitest in einem GitHub Actions Runner.
          Git und GitHub CLI sind verfÃ¼gbar.

          **TEST-AUFGABE:** Analysiere die Repository-Struktur

          FÃ¼hre aus:
          1. Zeige die Struktur von src/ mit Unterverzeichnissen: `find src -type d | head -20`
          2. ZÃ¤hle Dateien in jedem src/ Unterverzeichnis:
             - Domain: `find src/domain -type f 2>/dev/null | wc -l`
             - Application: `find src/application -type f 2>/dev/null | wc -l`
             - Infrastructure: `find src/infrastructure -type f 2>/dev/null | wc -l`
             - Framework: `find src/framework -type f 2>/dev/null | wc -l`
          3. Zeige die grÃ¶ÃŸten 5 TypeScript-Dateien (nach Zeilen): `find src -name "*.ts" -exec wc -l {} + 2>/dev/null | sort -rn | head -5`

          Gib alle Ergebnisse aus.
          EOF
              ;;
            "git-history")
              cat > /tmp/test-prompt.md << 'EOF'
          Du arbeitest in einem GitHub Actions Runner.
          Git und GitHub CLI sind verfÃ¼gbar.

          **TEST-AUFGABE:**
          1. Zeige den letzten Commit: `git log -1 --pretty=format:"%H %s %an %ad"`
          2. ZÃ¤hle alle Commits: `git rev-list --count HEAD`
          3. Zeige die letzten 5 geÃ¤nderten Dateien: `git log --name-only --pretty=format: -- -1 | grep -v '^$' | head -5`
          4. Zeige Commit-Statistik: `git log --oneline | head -5`

          Gib die Ergebnisse aus.
          EOF
              ;;
            "toon-comparison")
              # Dieser Test wird separat behandelt
              echo "toon-comparison" > /tmp/test-type.txt
              ;;
          esac

          echo "âœ… Test prompt created for type: $TEST_TYPE"

      - name: Run TOON Comparison Test
        if: github.event.inputs.test_type == 'toon-comparison'
        env:
          CURSOR_API_KEY: ${{ secrets.CURSOR_API_KEY }}
          CURSOR_AI_MODEL: ${{ secrets.CURSOR_AI_MODEL || 'sonnet-4.5' }}
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "ðŸ§ª Running TOON Comparison Test..."

          # Stelle sicher, dass eine TOON-Bibliothek installiert ist
          echo "ðŸ“¦ Installiere TOON-Bibliotheken..."
          python3 -m pip install toon-formatter python-toon toons 2>&1 | grep -v "already satisfied" || true

          # Verifiziere Installation - teste verschiedene Import-Namen
          if python3 -c "import toon_formatter" 2>/dev/null || \
             python3 -c "import toon" 2>/dev/null || \
             python3 -c "import toons" 2>/dev/null || \
             python3 -c "from toon_formatter import dumps, loads" 2>/dev/null || \
             python3 -c "from toon import dumps, loads" 2>/dev/null; then
            echo "âœ… TOON-Bibliothek erfolgreich installiert und importierbar"
          else
            echo "âš ï¸ Direkter Import-Test fehlgeschlagen, aber Skript wird es selbst versuchen"
            echo "Das Skript versucht automatisch verschiedene Bibliotheken"
          fi

          # Stelle sicher, dass GitHub CLI authentifiziert ist
          if [ -z "$GH_TOKEN" ]; then
            echo "âš ï¸ Warning: GH_TOKEN not set"
          else
            echo "âœ… GitHub CLI authenticated"
            export GH_TOKEN
          fi

          # Erstelle Test-Datenstruktur (Beispiel-Analyse-Ergebnis)
          cat > /tmp/test-data.json << 'JSON_EOF'
          {
            "summary": {
              "total_issues": 5,
              "files_analyzed": 10,
              "by_type": {
                "solid_violation": 2,
                "result_pattern_violation": 1,
                "architecture_violation": 1,
                "code_smell": 1,
                "bug": 0
              },
              "by_severity": {
                "critical": 0,
                "high": 2,
                "medium": 2,
                "low": 1
              }
            },
            "issues": [
              {
                "type": "solid_violation",
                "solid_principle": "SRP",
                "severity": "high",
                "file": "src/application/handlers/test-handler.ts",
                "line": 42,
                "column": 10,
                "title": "Single Responsibility Principle Verletzung",
                "description": "Die Methode hat zu viele Verantwortlichkeiten und sollte aufgeteilt werden.",
                "current_code": "handle(event: TestEvent): void { ... }",
                "recommendation": "In kleinere Methoden aufteilen",
                "references": ["ADR-0001"]
              },
              {
                "type": "result_pattern_violation",
                "severity": "medium",
                "file": "src/application/services/test-service.ts",
                "line": 15,
                "column": 5,
                "title": "Result-Pattern nicht vollstÃ¤ndig geprÃ¼ft",
                "description": "Result-Wert wird nicht vollstÃ¤ndig behandelt.",
                "current_code": "if (result.ok) { ... }",
                "recommendation": "Fehlerfall explizit behandeln",
                "references": []
              }
            ]
          }
          JSON_EOF

          # Konvertiere zu TOON
          echo "ðŸ”„ Konvertiere JSON zu TOON..."
          python3 scripts/toon-converter.py json-to-toon /tmp/test-data.json /tmp/test-data.toon

          # Erstelle zwei identische Prompts mit unterschiedlichen Formaten
          cat > /tmp/prompt-json.md << 'PROMPT_EOF'
          Du arbeitest in einem GitHub Actions Runner.
          Git und GitHub CLI sind verfÃ¼gbar.

          **TEST-AUFGABE:** Analysiere folgende Code-Review-Ergebnisse und gib eine Zusammenfassung aus.

          Die Ergebnisse sind im JSON-Format:

          {
            "summary": {
              "total_issues": 5,
              "files_analyzed": 10,
              "by_type": {
                "solid_violation": 2,
                "result_pattern_violation": 1,
                "architecture_violation": 1,
                "code_smell": 1,
                "bug": 0
              },
              "by_severity": {
                "critical": 0,
                "high": 2,
                "medium": 2,
                "low": 1
              }
            },
            "issues": [
              {
                "type": "solid_violation",
                "solid_principle": "SRP",
                "severity": "high",
                "file": "src/application/handlers/test-handler.ts",
                "line": 42,
                "column": 10,
                "title": "Single Responsibility Principle Verletzung",
                "description": "Die Methode hat zu viele Verantwortlichkeiten und sollte aufgeteilt werden.",
                "current_code": "handle(event: TestEvent): void { ... }",
                "recommendation": "In kleinere Methoden aufteilen",
                "references": ["ADR-0001"]
              },
              {
                "type": "result_pattern_violation",
                "severity": "medium",
                "file": "src/application/services/test-service.ts",
                "line": 15,
                "column": 5,
                "title": "Result-Pattern nicht vollstÃ¤ndig geprÃ¼ft",
                "description": "Result-Wert wird nicht vollstÃ¤ndig behandelt.",
                "current_code": "if (result.ok) { ... }",
                "recommendation": "Fehlerfall explizit behandeln",
                "references": []
              }
            ]
          }

          Gib eine kurze Zusammenfassung der gefundenen Probleme aus.
          PROMPT_EOF

          TOON_DATA=$(cat /tmp/test-data.toon)
          cat > /tmp/prompt-toon.md << PROMPT_EOF
          Du arbeitest in einem GitHub Actions Runner.
          Git und GitHub CLI sind verfÃ¼gbar.

          **TEST-AUFGABE:** Analysiere folgende Code-Review-Ergebnisse und gib eine Zusammenfassung aus.

          Die Ergebnisse sind im TOON-Format:

          ${TOON_DATA}

          Gib eine kurze Zusammenfassung der gefundenen Probleme aus.
          PROMPT_EOF

          # Funktion zum Messen von Token-Verbrauch (SchÃ¤tzung)
          estimate_tokens() {
            local text="$1"
            local cleaned=$(echo "$text" | tr -d '\n' | tr -s ' ')
            local chars=${#cleaned}
            echo $((chars / 4))  # ~4 Zeichen pro Token
          }

          # PrÃ¼fe ob cursor-agent verfÃ¼gbar ist
          if [ "$cursor_available" = "false" ]; then
            echo "âš ï¸ cursor-agent nicht verfÃ¼gbar - AI-Tests werden Ã¼bersprungen"
            echo "ðŸ“Š TOON-Konvertierung und Token-Vergleich werden trotzdem durchgefÃ¼hrt"

            # Erstelle Dummy-Outputs fÃ¼r Vergleich
            echo "cursor-agent nicht verfÃ¼gbar" > /tmp/test-output-json.txt
            echo "cursor-agent nicht verfÃ¼gbar" > /tmp/test-output-toon.txt
            PROMPT_JSON_TOKENS=334
            PROMPT_TOON_TOKENS=296
            OUTPUT_JSON_TOKENS=0
            OUTPUT_TOON_TOKENS=0
            DURATION_JSON=0
            DURATION_TOON=0
          else
            # Test 1: JSON-Format
            echo ""
            echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
            echo "ðŸ“Š TEST 1: JSON-Format"
            echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

            PROMPT_JSON=$(cat /tmp/prompt-json.md)
            PROMPT_JSON_SIZE=$(echo -n "$PROMPT_JSON" | wc -c)
            PROMPT_JSON_TOKENS=$(estimate_tokens "$PROMPT_JSON")

            echo "Prompt-GrÃ¶ÃŸe: ${PROMPT_JSON_SIZE} Bytes"
            echo "GeschÃ¤tzte Input-Tokens: ${PROMPT_JSON_TOKENS}"
            echo ""
            echo "ðŸš€ Calling cursor-agent mit JSON-Format..."

            START_TIME=$(date +%s)
            timeout 600 cursor-agent -p "$PROMPT_JSON" --model "${CURSOR_AI_MODEL:-sonnet-4.5}" > /tmp/test-output-json.txt 2>&1 || {
              EXIT_CODE=$?
              if [ $EXIT_CODE -eq 124 ]; then
                echo "â±ï¸ Test timed out after 10 minutes"
              else
                echo "âš ï¸ cursor-agent exited with code: $EXIT_CODE"
              fi
            }
            END_TIME=$(date +%s)
            DURATION_JSON=$((END_TIME - START_TIME))

            OUTPUT_JSON=$(cat /tmp/test-output-json.txt)
            OUTPUT_JSON_SIZE=$(echo -n "$OUTPUT_JSON" | wc -c)
            OUTPUT_JSON_TOKENS=$(estimate_tokens "$OUTPUT_JSON")

            echo "Output-GrÃ¶ÃŸe: ${OUTPUT_JSON_SIZE} Bytes"
            echo "GeschÃ¤tzte Output-Tokens: ${OUTPUT_JSON_TOKENS}"
            echo "Dauer: ${DURATION_JSON} Sekunden"
            echo "Gesamt-Tokens (geschÃ¤tzt): $((PROMPT_JSON_TOKENS + OUTPUT_JSON_TOKENS))"

            # Test 2: TOON-Format
            echo ""
            echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
            echo "ðŸ“Š TEST 2: TOON-Format"
            echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

            PROMPT_TOON=$(cat /tmp/prompt-toon.md)
            PROMPT_TOON_SIZE=$(echo -n "$PROMPT_TOON" | wc -c)
            PROMPT_TOON_TOKENS=$(estimate_tokens "$PROMPT_TOON")

            echo "Prompt-GrÃ¶ÃŸe: ${PROMPT_TOON_SIZE} Bytes"
            echo "GeschÃ¤tzte Input-Tokens: ${PROMPT_TOON_TOKENS}"
            echo ""
            echo "ðŸš€ Calling cursor-agent mit TOON-Format..."

            START_TIME=$(date +%s)
            timeout 600 cursor-agent -p "$PROMPT_TOON" --model "${CURSOR_AI_MODEL:-sonnet-4.5}" > /tmp/test-output-toon.txt 2>&1 || {
              EXIT_CODE=$?
              if [ $EXIT_CODE -eq 124 ]; then
                echo "â±ï¸ Test timed out after 10 minutes"
              else
                echo "âš ï¸ cursor-agent exited with code: $EXIT_CODE"
              fi
            }
            END_TIME=$(date +%s)
            DURATION_TOON=$((END_TIME - START_TIME))

            OUTPUT_TOON=$(cat /tmp/test-output-toon.txt)
            OUTPUT_TOON_SIZE=$(echo -n "$OUTPUT_TOON" | wc -c)
            OUTPUT_TOON_TOKENS=$(estimate_tokens "$OUTPUT_TOON")

            echo "Output-GrÃ¶ÃŸe: ${OUTPUT_TOON_SIZE} Bytes"
            echo "GeschÃ¤tzte Output-Tokens: ${OUTPUT_TOON_TOKENS}"
            echo "Dauer: ${DURATION_TOON} Sekunden"
            echo "Gesamt-Tokens (geschÃ¤tzt): $((PROMPT_TOON_TOKENS + OUTPUT_TOON_TOKENS))"
          fi

          # Vergleich
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ðŸ“ˆ VERGLEICH"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

          INPUT_SAVED=$((PROMPT_JSON_TOKENS - PROMPT_TOON_TOKENS))
          INPUT_SAVED_PERCENT=$((INPUT_SAVED * 100 / PROMPT_JSON_TOKENS))

          TOTAL_JSON=$((PROMPT_JSON_TOKENS + OUTPUT_JSON_TOKENS))
          TOTAL_TOON=$((PROMPT_TOON_TOKENS + OUTPUT_TOON_TOKENS))
          TOTAL_SAVED=$((TOTAL_JSON - TOTAL_TOON))
          TOTAL_SAVED_PERCENT=$((TOTAL_SAVED * 100 / TOTAL_JSON))

          echo "Input-Tokens:"
          echo "  JSON: ${PROMPT_JSON_TOKENS}"
          echo "  TOON: ${PROMPT_TOON_TOKENS}"
          echo "  Einsparung: ${INPUT_SAVED} Tokens (${INPUT_SAVED_PERCENT}%)"
          echo ""
          echo "Output-Tokens:"
          echo "  JSON: ${OUTPUT_JSON_TOKENS}"
          echo "  TOON: ${OUTPUT_TOON_TOKENS}"
          echo ""
          echo "Gesamt-Tokens:"
          echo "  JSON: ${TOTAL_JSON}"
          echo "  TOON: ${TOTAL_TOON}"
          echo "  Einsparung: ${TOTAL_SAVED} Tokens (${TOTAL_SAVED_PERCENT}%)"
          echo ""
          echo "Laufzeit:"
          echo "  JSON: ${DURATION_JSON}s"
          echo "  TOON: ${DURATION_TOON}s"

          # Speichere Ergebnisse
          mkdir -p test-results
          cp /tmp/test-output-json.txt test-results/output-json.txt
          cp /tmp/test-output-toon.txt test-results/output-toon.txt
          cp /tmp/prompt-json.md test-results/prompt-json.md
          cp /tmp/prompt-toon.md test-results/prompt-toon.md
          cp /tmp/test-data.json test-results/test-data.json
          cp /tmp/test-data.toon test-results/test-data.toon

          # Erstelle Vergleichs-Report
          cat > test-results/comparison-report.txt << REPORT_EOF
          TOON vs JSON Vergleichs-Report
          =================================

          Input-Tokens:
            JSON: ${PROMPT_JSON_TOKENS}
            TOON: ${PROMPT_TOON_TOKENS}
            Einsparung: ${INPUT_SAVED} Tokens (${INPUT_SAVED_PERCENT}%)

          Output-Tokens:
            JSON: ${OUTPUT_JSON_TOKENS}
            TOON: ${OUTPUT_TOON_TOKENS}

          Gesamt-Tokens:
            JSON: ${TOTAL_JSON}
            TOON: ${TOTAL_TOON}
            Einsparung: ${TOTAL_SAVED} Tokens (${TOTAL_SAVED_PERCENT}%)

          Laufzeit:
            JSON: ${DURATION_JSON}s
            TOON: ${DURATION_TOON}s
          REPORT_EOF

          echo ""
          echo "âœ… Vergleichstest abgeschlossen!"
          echo "ðŸ“ Ergebnisse gespeichert in test-results/"

      - name: Run Cursor AI Test
        if: github.event.inputs.test_type != 'toon-comparison'
        env:
          CURSOR_API_KEY: ${{ secrets.CURSOR_API_KEY }}
          CURSOR_AI_MODEL: ${{ secrets.CURSOR_AI_MODEL || 'sonnet-4.5' }}
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "ðŸ§ª Running repository access test..."
          echo "Test Type: ${{ github.event.inputs.test_type }}"

          # Stelle sicher, dass GitHub CLI authentifiziert ist
          if [ -z "$GH_TOKEN" ]; then
            echo "âš ï¸ Warning: GH_TOKEN not set"
          else
            echo "âœ… GitHub CLI authenticated"
            export GH_TOKEN
          fi

          # Lese Prompt
          PROMPT=$(cat /tmp/test-prompt.md)
          echo ""
          echo "ðŸ“„ Prompt (first 500 chars):"
          echo "$PROMPT" | head -c 500
          echo "..."
          echo ""

          # Rufe cursor-agent auf
          echo "ðŸš€ Calling cursor-agent..."
          timeout 600 cursor-agent -p "$PROMPT" --model "${CURSOR_AI_MODEL:-sonnet-4.5}" > /tmp/test-output.txt 2>&1 || {
            EXIT_CODE=$?
            if [ $EXIT_CODE -eq 124 ]; then
              echo "â±ï¸ Test timed out after 10 minutes"
            else
              echo "âš ï¸ cursor-agent exited with code: $EXIT_CODE"
            fi
          }

          # Zeige Output
          echo ""
          echo "ðŸ“Š Test Output:"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          cat /tmp/test-output.txt
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

          # Speichere Output auch als Artifact
          echo "ðŸ’¾ Saving output as artifact..."
          mkdir -p test-results
          cp /tmp/test-output.txt test-results/output.txt
          cp /tmp/test-prompt.md test-results/prompt.md

      - name: Upload test results
        uses: actions/upload-artifact@v5
        if: always()
        with:
          name: repository-access-test-${{ github.event.inputs.test_type }}-${{ github.run_id }}
          path: test-results/
          retention-days: 7

      - name: Test Summary
        if: always()
        run: |
          TEST_TYPE="${{ github.event.inputs.test_type }}"

          if [ "$TEST_TYPE" == "toon-comparison" ]; then
            echo "## ðŸ§ª TOON vs JSON Vergleichstest" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Model:** ${CURSOR_AI_MODEL:-sonnet-4.5}" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            if [ -f test-results/comparison-report.txt ]; then
              echo "### ðŸ“Š Vergleichsergebnisse" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
              cat test-results/comparison-report.txt >> $GITHUB_STEP_SUMMARY
              echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
            fi

            echo "### JSON-Output (Ausschnitt)" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            head -50 test-results/output-json.txt >> $GITHUB_STEP_SUMMARY 2>/dev/null || echo "No output" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            echo "### TOON-Output (Ausschnitt)" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            head -50 test-results/output-toon.txt >> $GITHUB_STEP_SUMMARY 2>/dev/null || echo "No output" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            echo "ðŸ“¦ VollstÃ¤ndige Ergebnisse verfÃ¼gbar als Artifact" >> $GITHUB_STEP_SUMMARY
          else
            echo "## ðŸ§ª Repository Access Test Results" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Test Type:** $TEST_TYPE" >> $GITHUB_STEP_SUMMARY
            echo "**Model:** ${CURSOR_AI_MODEL:-sonnet-4.5}" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Output Preview" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            head -100 /tmp/test-output.txt >> $GITHUB_STEP_SUMMARY 2>/dev/null || echo "No output" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "ðŸ“¦ Full output available as artifact" >> $GITHUB_STEP_SUMMARY
          fi

