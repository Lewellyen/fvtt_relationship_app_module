name: AI Code Review & Quality Analysis

on:
  workflow_dispatch:

jobs:
  ai-code-review:
    name: AI Code Analysis & Issue Creation
    runs-on: ubuntu-latest

    permissions:
      contents: read  # Repository-Inhalt lesen (f√ºr git, gh api)
      issues: write   # Issues erstellen
      pull-requests: read  # PR-Informationen lesen

    steps:
      - name: Checkout code
        uses: actions/checkout@v6
        with:
          ref: ${{ github.event.workflow_run.head_branch || github.ref }}
          fetch-depth: 0 # Full history for better context

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: "20.x"
          cache: "npm"

      - name: Install dependencies
        run: npm ci

      - name: Setup Python for issue creation script
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Python dependencies
        run: |
          pip install toon-formatter python-toon toons

      - name: Cache Cursor Agent
        uses: actions/cache@v4
        id: cursor-cache
        with:
          path: ~/.cursor
          key: cursor-agent-${{ runner.os }}-v2
          restore-keys: |
            cursor-agent-${{ runner.os }}-

      - name: Install Cursor CLI
        id: cursor-setup
        continue-on-error: true
        run: |
          # Pr√ºfe ob cursor-agent bereits im Cache vorhanden ist
          if [ "${{ steps.cursor-cache.outputs.cache-hit }}" = "true" ]; then
            if [ -f "$HOME/.cursor/bin/cursor-agent" ] || [ -f "$HOME/.local/bin/cursor-agent" ]; then
              echo "‚úÖ cursor-agent bereits im Cache vorhanden"
              exit 0
            else
              echo "‚ö†Ô∏è Cache-Hit aber cursor-agent nicht gefunden - Cache ist leer, installiere neu..."
            fi
          fi

          echo "Installing Cursor CLI..."
          curl https://cursor.com/install -fsS | bash || {
            echo "‚ö†Ô∏è curl failed, trying wget..."
            wget -qO- https://cursor.com/install | bash || {
              echo "‚ùå All installation methods failed"
              exit 0  # Workflow continues
            }
          }

          # F√ºge alle m√∂glichen Pfade zum PATH hinzu
          echo "$HOME/.cursor/bin" >> $GITHUB_PATH
          echo "$HOME/.local/bin" >> $GITHUB_PATH

          # Verifiziere dass Installation erfolgreich war
          if [ -f "$HOME/.cursor/bin/cursor-agent" ] || [ -f "$HOME/.local/bin/cursor-agent" ]; then
            echo "‚úÖ Installation erfolgreich - cursor-agent gefunden"
          else
            echo "‚ö†Ô∏è Installation abgeschlossen aber cursor-agent nicht gefunden"
          fi

      - name: Verify Cursor CLI
        run: |
          # F√ºge m√∂gliche Pfade zum PATH hinzu (auch nach Cache-Restore)
          echo "$HOME/.cursor/bin" >> $GITHUB_PATH
          echo "$HOME/.local/bin" >> $GITHUB_PATH
          export PATH="$HOME/.cursor/bin:$HOME/.local/bin:$PATH"

          # Pr√ºfe verschiedene m√∂gliche Pfade
          CURSOR_AGENT=""
          if command -v cursor-agent &> /dev/null; then
            CURSOR_AGENT=$(command -v cursor-agent)
            echo "‚úÖ cursor-agent gefunden im PATH: $CURSOR_AGENT"
          elif [ -f "$HOME/.cursor/bin/cursor-agent" ]; then
            CURSOR_AGENT="$HOME/.cursor/bin/cursor-agent"
            echo "‚úÖ cursor-agent gefunden: $CURSOR_AGENT"
            chmod +x "$CURSOR_AGENT" || true
          elif [ -f "$HOME/.local/bin/cursor-agent" ]; then
            CURSOR_AGENT="$HOME/.local/bin/cursor-agent"
            echo "‚úÖ cursor-agent gefunden: $CURSOR_AGENT"
            chmod +x "$CURSOR_AGENT" || true
          else
            echo "‚ö†Ô∏è cursor-agent nicht in Standard-Pfaden gefunden"
            echo "Searching in $HOME..."
            FOUND=$(find "$HOME" -name "cursor-agent" -type f 2>/dev/null | head -1)
            if [ -n "$FOUND" ]; then
              CURSOR_AGENT="$FOUND"
              echo "‚úÖ cursor-agent gefunden: $CURSOR_AGENT"
              chmod +x "$CURSOR_AGENT" || true
              # F√ºge zum PATH hinzu
              DIR=$(dirname "$CURSOR_AGENT")
              echo "$DIR" >> $GITHUB_PATH
              export PATH="$DIR:$PATH"
            fi
          fi

          if [ -n "$CURSOR_AGENT" ]; then
            echo "‚úÖ cursor-agent verf√ºgbar"
            echo "cursor_available=true" >> $GITHUB_ENV
            echo "cursor_agent_path=$CURSOR_AGENT" >> $GITHUB_ENV
            ls -la "$CURSOR_AGENT" || true
          else
            echo "‚ö†Ô∏è cursor-agent nicht verf√ºgbar"
            echo "cursor_available=false" >> $GITHUB_ENV
            echo "Cache-Inhalt pr√ºfen..."
            ls -la "$HOME/.cursor" || echo "~/.cursor existiert nicht"
            ls -la "$HOME/.cursor/bin" 2>/dev/null || echo "~/.cursor/bin existiert nicht"
          fi

      - name: Get changed files since last commit
        id: changed-files
        run: |
          COMMIT_SHA="${{ github.sha }}"
          echo "Analyzing latest commit: $COMMIT_SHA"

          # Hole ge√§nderte TypeScript-Dateien
          git diff --name-only --diff-filter=ACMR HEAD~1 HEAD | grep -E '\.(ts|js|svelte)$' | grep -v '\.test\.' | grep -v '\.spec\.' > changed_files.txt || true

          if [ ! -s changed_files.txt ]; then
            echo "No relevant files changed, skipping analysis"
            echo "skip=true" >> $GITHUB_OUTPUT
          else
            echo "Changed files:"
            cat changed_files.txt
            echo "skip=false" >> $GITHUB_OUTPUT
            echo "files=$(cat changed_files.txt | tr '\n' ',' | sed 's/,$//')" >> $GITHUB_OUTPUT
          fi

      - name: Create analysis prompt
        if: steps.changed-files.outputs.skip == 'false'
        run: |
          cat > /tmp/analysis-prompt.md << 'PROMPT_EOF'
          Du arbeitest in einem GitHub Actions Runner.

          Die GitHub CLI ist als `gh` verf√ºgbar und √ºber `GH_TOKEN` authentifiziert. Git ist verf√ºgbar.
          Du hast vollst√§ndigen Lesezugriff auf das Repository.

          # Kontext:
          - Repo: ${{ github.repository }}
          - Branch: ${{ github.ref_name }}
          - Commit: ${{ github.sha }}
          - Workflow Run: ${{ github.run_id }}

          # Deine Aufgabe:

          Du bist ein erfahrener Code-Reviewer f√ºr ein TypeScript/Foundry VTT Modul-Projekt.
          Analysiere die **ge√§nderten Dateien** auf Code-Qualit√§t, Architektur-Konformit√§t und potentielle Probleme.

          **WICHTIG:** Nutze `git diff`, `git show`, oder `gh api` um die ge√§nderten Dateien zu finden und zu lesen.
          Du kannst auch `git log` nutzen um zu sehen, was ge√§ndert wurde.
          Du musst nicht Code hier im Prompt haben - du kannst alle Dateien selbst lesen!

          ## Projektkontext

          Das Projekt verwendet:
          - **Clean Architecture** mit 4 Schichten: Domain ‚Üí Application ‚Üí Infrastructure ‚Üí Framework
          - **Result-Pattern** statt Exceptions (siehe ADR-0001)
          - **SOLID-Prinzipien** durchg√§ngig
          - **Port-Adapter-Pattern** f√ºr Foundry VTT Version-Kompatibilit√§t
          - **Dependency Inversion Principle (DIP)**: Abh√§ngigkeiten nur zu Interfaces, nie zu Implementierungen

          ## Analyseschwerpunkte

          ### 1. SOLID-Prinzipien Pr√ºfung

          **Single Responsibility Principle (SRP):**
          - Hat jede Klasse/Interface nur eine Verantwortlichkeit?
          - Gibt es "God Classes" die zu viel tun?
          - Sind Methoden fokussiert auf eine Aufgabe?

          **Open/Closed Principle (OCP):**
          - Ist Code erweiterbar ohne Modifikation?
          - Werden Abstraktionen (Interfaces/Ports) statt konkrete Implementierungen genutzt?
          - Gibt es unn√∂tige switch/if-Ketten die durch Polymorphismus ersetzt werden k√∂nnten?

          **Liskov Substitution Principle (LSP):**
          - K√∂nnen Implementierungen ihre Interfaces vollst√§ndig ersetzen?
          - Gibt es Verletzungen des Vertrags (z.B. st√§rkere Pr√§-/Postconditions)?

          **Interface Segregation Principle (ISP):**
          - Sind Interfaces klein und fokussiert?
          - M√ºssen Implementierungen Methoden implementieren die sie nicht nutzen?
          - Gibt es gro√üe "Fat Interfaces" die aufgeteilt werden sollten?

          **Dependency Inversion Principle (DIP):**
          - Abh√§ngigkeiten nur zu Abstraktionen (Interfaces, Ports)?
          - Keine direkten Abh√§ngigkeiten zu konkreten Implementierungen?
          - Verwendung von DI-Container f√ºr Abh√§ngigkeiten?
          - Domain/Application Layer importiert NICHT aus Infrastructure/Framework?

          ### 2. Result/Either-Pattern Konformit√§t

          - Werden Funktionen die fehlschlagen k√∂nnen als `Result<T, E>` zur√ºckgegeben?
          - Werden Exceptions nur f√ºr unerwartete Fehler geworfen (Assertion Failures, Programming Errors)?
          - Werden Result-Werte korrekt behandelt (if/else checks, match(), andThen())?
          - Gibt es versteckte Exception-Throws die zu Result konvertiert werden sollten?
          - Nutzung von `ok()`, `err()`, `map()`, `andThen()`, `match()` Utilities?

          **Ausnahmen (Exceptions erlaubt):**
          - √ñffentliche API (`module-api.ts`): `container.resolve()` f√ºr externe Module
          - Unerwartete Fehler: Assertion Failures, Programming Errors

          ### 3. Clean Architecture Schichttrennung

          **Layer-Regeln:**
          - Domain Layer: Keine Foundry-Dependencies, nur Business-Logik, Port-Interfaces
          - Application Layer: Nutzt Domain Ports, keine direkten Foundry-Calls
          - Infrastructure Layer: Foundry Adapter, Port-Implementierungen, DI-Infrastruktur
          - Framework Layer: Bootstrap, Config, API Exposition

          **Dependency-Regel:**
          - √Ñu√üere Schichten ‚Üí innere Schichten ‚úÖ
          - Innere Schichten ‚Üí √§u√üere Schichten ‚ùå
          - Domain importiert NICHT aus Infrastructure/Framework
          - Application importiert NICHT aus Framework

          **Import-Pfade pr√ºfen:**
          - `src/domain/` darf NICHT importieren aus: `src/infrastructure/`, `src/framework/`
          - `src/application/` darf NICHT importieren aus: `src/framework/`
          - `@/domain/`, `@/application/` d√ºrfen keine Foundry-spezifischen Typen verwenden

          ### 4. Port-Adapter-Pattern

          - Werden Foundry API-Calls nur in Adapter-Schicht gemacht?
          - Ports als Interfaces definiert?
          - Version-spezifische Implementierungen in `ports/v13/`, `ports/v14/`?
          - Service-Wrapper nutzen Port-Selector f√ºr Version-Auswahl?
          - Lazy Instantiation f√ºr Ports (keine sofortige Instanziierung aller Versionen)?

          ### 5. Code Smells & Anti-Patterns

          **Code Smells:**
          - Long Methods (> 50 Zeilen)
          - Large Classes (> 500 Zeilen)
          - Feature Envy (Methoden nutzen mehr fremde als eigene Daten)
          - Data Clumps (Gruppen von Daten die zusammen geh√∂ren sollten)
          - Primitive Obsession (Strings/Numbers statt Value Objects)
          - Duplicate Code
          - Magic Numbers/Strings

          **Anti-Patterns:**
          - God Object / God Class
          - Swiss Army Knife Interface
          - Anemic Domain Model
          - Service Locator Pattern (au√üer in Config-Layer)
          - Tight Coupling
          - Circular Dependencies
          - Leaky Abstractions

          ### 6. Bugs & Fehlerquellen

          - Unbehandelte Fehler (Result nicht gepr√ºft)
          - Race Conditions (async/await Probleme)
          - Memory Leaks (Event Listeners nicht entfernt, Closures)
          - Null/Undefined Checks fehlen
          - Type Assertions ohne Validierung
          - Side Effects in pure functions
          - Mutable Shared State

          ## Output-Format

          **WICHTIG:** Du MUSST die Analyse-Ergebnisse AUSSCHLIESSLICH im TOON-Format (Token-Oriented Object Notation) ausgeben - KEIN Markdown, KEIN JSON, KEIN zus√§tzlicher Text vor oder nach dem TOON!

          TOON ist ein kompaktes Format das Token spart. Beginne direkt mit dem TOON-Format, KEINE Markdown-Formatierung, KEIN Code-Block!

          TOON-Format Beispiel:
          summary{total_issues,by_type,by_severity}:
            total_issues: 0
            by_type{solid_violation,result_pattern_violation,architecture_violation,code_smell,bug}:
              solid_violation: 0
              result_pattern_violation: 0
              architecture_violation: 0
              code_smell: 0
              bug: 0
            by_severity{critical,high,medium,low}:
              critical: 0
              high: 0
              medium: 0
              low: 0
          issues[0]{type,solid_principle,severity,file,line,column,title,description,current_code,recommendation,references}:
            type: solid_violation
            solid_principle: SRP
            severity: high
            file: src/path/to/file.ts
            line: 42
            column: 10
            title: Kurze pr√§gnante Beschreibung
            description: Detaillierte Beschreibung des Problems
            current_code: Relevanter Code-Ausschnitt
            recommendation: Konkreter Vorschlag zur Behebung
            references[1]: ADR-0001
          ```

          **Severity-Kriterien:**
          - **critical**: Kritischer Bug mit hohem Runtime-Risiko, fundamentale Architektur-Verletzung
          - **high**: Versto√ü gegen fundamentale Prinzipien (DIP, Layer-Trennung), Bug mit Runtime-Risiko
          - **medium**: SOLID-Versto√ü, Result-Pattern-Missbrauch, Code Smell mit Wartbarkeits-Impact
          - **low**: Code Smell ohne direkten Impact, Verbesserungsvorschlag

          ## Wichtige Hinweise

          - Analysiere nur die ge√§nderten Dateien, nicht den gesamten Codebase
          - Sei pr√§zise und konkrete - vermeide vage Hinweise
          - Ber√ºcksichtige Projekt-spezifische Patterns (Result-Pattern ist Standard!)
          - Bevorzuge konstruktive Verbesserungsvorschl√§ge
          - Ignoriere bereits dokumentierte Ausnahmen (siehe quality-gates/)
          - Fokussiere auf neue Probleme, nicht auf Legacy-Code

          ## Zu analysierende Dateien

          Finde und analysiere die ge√§nderten Dateien selbst:
          1. Nutze `git diff HEAD~1` oder `git diff main` um ge√§nderte Dateien zu finden
          2. Oder nutze `gh api repos/{owner}/{repo}/pulls/{pr}/files` falls es einen PR gibt
          3. Lies die ge√§nderten Dateien mit `git show` oder `cat`
          4. Analysiere die √Ñnderungen im Kontext des gesamten Projekts

          **Hinweis:** Diese Liste dient nur als Orientierung - finde die ge√§nderten Dateien selbst!
          PROMPT_EOF

          # F√ºge nur eine Liste der ge√§nderten Dateien hinzu (KEIN Code!)
          if [ -f changed_files.txt ]; then
            echo "" >> /tmp/analysis-prompt.md
            echo "**Ge√§nderte Dateien (als Orientierung):**" >> /tmp/analysis-prompt.md
            echo "" >> /tmp/analysis-prompt.md
            echo "\`\`\`" >> /tmp/analysis-prompt.md
            cat changed_files.txt >> /tmp/analysis-prompt.md || true
            echo "\`\`\`" >> /tmp/analysis-prompt.md
            echo "" >> /tmp/analysis-prompt.md
            echo "Lies diese Dateien selbst mit \`git show\` oder \`cat\` und analysiere sie!" >> /tmp/analysis-prompt.md
          fi

      - name: Run Cursor AI Analysis
        if: steps.changed-files.outputs.skip == 'false'
        id: analysis
        env:
          CURSOR_API_KEY: ${{ secrets.CURSOR_API_KEY }}
          CURSOR_AI_MODEL: ${{ secrets.CURSOR_AI_MODEL || 'sonnet-4.5' }}
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        continue-on-error: true
        run: |
          echo "Starting Cursor AI analysis..."

          # Setze Standard-Modell falls nicht als Secret definiert
          CURSOR_AI_MODEL="${CURSOR_AI_MODEL:-sonnet-4.5}"
          echo "Using model: $CURSOR_AI_MODEL"

          # Stelle sicher, dass GitHub CLI authentifiziert ist
          # GH_TOKEN wird von GitHub Actions automatisch bereitgestellt
          if [ -z "$GH_TOKEN" ]; then
            echo "‚ö†Ô∏è Warning: GH_TOKEN not set, GitHub CLI may not work"
          else
            echo "‚úÖ GitHub CLI authenticated via GH_TOKEN"
            # Exportiere GH_TOKEN f√ºr GitHub CLI
            export GH_TOKEN
          fi

          # Prompt-Gr√∂√üe pr√ºfen
          PROMPT_SIZE=$(wc -c < /tmp/analysis-prompt.md)
          echo "Prompt size: $PROMPT_SIZE bytes"

          # Lese Prompt aus Datei und √ºbergebe direkt an cursor-agent (wie in der offiziellen Dokumentation)
          echo "Reading prompt and calling cursor-agent directly..."
          PROMPT=$(cat /tmp/analysis-prompt.md)

          # Rufe cursor-agent direkt auf (wie im offiziellen Beispiel)
          # Timeout von 30 Minuten (1800 Sekunden) f√ºr gro√üe Analysen
          timeout 1800 cursor-agent -p "$PROMPT" --model "$CURSOR_AI_MODEL" > /tmp/analysis-output.json 2>&1 || {
            EXIT_CODE=$?
            if [ $EXIT_CODE -eq 124 ]; then
              echo "Analysis timed out after 30 minutes"
            else
              echo "Cursor AI analysis completed with exit code: $EXIT_CODE"
              echo "This may be normal - checking for JSON in output..."
            fi
            # Versuche JSON zu extrahieren falls es in Text eingebettet ist
            grep -oP '(?<=\`\`\`json\n)(.*?)(?=\n\`\`\`)|(?<=\{)(.*?)(?=\})' /tmp/analysis-output.json | head -1 > /tmp/analysis-extracted.json || true
          }
          EXIT_CODE=${EXIT_CODE:-0}

          # Pr√ºfe ob Output existiert
          if [ ! -f /tmp/analysis-output.json ] || [ ! -s /tmp/analysis-output.json ]; then
            echo "No analysis output generated"
            echo "skipped=true" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Speichere Raw-Output auch als TOON
          cp /tmp/analysis-output.json /tmp/analysis-output.toon

          # Versuche TOON-Extraktion (konvertiert automatisch zu JSON f√ºr Kompatibilit√§t)
          echo "Extracting TOON format from output..."
          if python3 scripts/ai-review-extract-toon.py; then
            echo "‚úÖ TOON extraction successful"
          else
            echo "‚ö†Ô∏è TOON extraction failed, trying JSON fallback..."
            # Fallback zu JSON (R√ºckw√§rtskompatibilit√§t)
            if ! python3 -m json.tool /tmp/analysis-output.json > /dev/null 2>&1; then
              python3 scripts/ai-review-extract-json.py
            fi
          fi

          echo "skipped=false" >> $GITHUB_OUTPUT

      - name: Prepare artifacts
        if: steps.changed-files.outputs.skip == 'false'
        run: |
          mkdir -p ai-review-artifacts

          # Kopiere Prompt
          if [ -f /tmp/analysis-prompt.md ]; then
            cp /tmp/analysis-prompt.md ai-review-artifacts/prompt.md
          fi

          # Kopiere Raw-Output
          if [ -f /tmp/analysis-output.json ]; then
            cp /tmp/analysis-output.json ai-review-artifacts/output-raw.txt
          fi

          # Kopiere TOON-Output
          if [ -f /tmp/analysis-output.toon ]; then
            cp /tmp/analysis-output.toon ai-review-artifacts/output.toon
          fi

          # Kopiere JSON-Output (nach Extraktion)
          if [ -f /tmp/analysis-output.json ]; then
            cp /tmp/analysis-output.json ai-review-artifacts/output.json
          fi

          # Erstelle Info-Datei
          cat > ai-review-artifacts/info.txt << EOF
          AI Code Review - Incremental Analysis
          =====================================

          Workflow: ${{ github.workflow }}
          Run ID: ${{ github.run_id }}
          Commit: ${{ github.sha }}
          Branch: ${{ github.ref_name }}

          Model: ${CURSOR_AI_MODEL:-sonnet-4.5}
          Format: TOON (Token-Oriented Object Notation)

          Files:
          - prompt.md: Original prompt sent to AI
          - output-raw.txt: Raw AI response
          - output.toon: Extracted TOON format
          - output.json: Converted JSON (for compatibility)
          EOF

      - name: Upload AI Review Artifacts
        if: steps.changed-files.outputs.skip == 'false'
        uses: actions/upload-artifact@v5
        with:
          name: ai-review-incremental-${{ github.run_id }}
          path: ai-review-artifacts/
          retention-days: 30

      - name: Parse results and create issues
        if: steps.changed-files.outputs.skip == 'false' && steps.analysis.outputs.skipped == 'false'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_SHA: ${{ github.event.workflow_run.head_sha || github.sha }}
        run: |
          python3 scripts/ai-review-create-issues.py

      - name: Create summary
        if: always()
        run: |
          echo "## ü§ñ AI Code Review abgeschlossen" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ steps.changed-files.outputs.skip }}" == "true" ]; then
            echo "‚è≠Ô∏è Keine relevanten Dateien ge√§ndert - Analyse √ºbersprungen" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ steps.analysis.outputs.skipped }}" == "true" ]; then
            echo "‚ö†Ô∏è Analyse konnte nicht ausgef√ºhrt werden (keine g√ºltigen Ergebnisse)" >> $GITHUB_STEP_SUMMARY
          else
            if [ -f /tmp/analysis-output.json ]; then
              python3 scripts/ai-review-summary.py >> $GITHUB_STEP_SUMMARY
            else
              echo "‚ö†Ô∏è Keine Analyse-Ergebnisse verf√ºgbar" >> $GITHUB_STEP_SUMMARY
            fi
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Workflow:** ${{ github.workflow }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** \`${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY
